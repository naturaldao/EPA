#### 5.2.2 伦理对齐性治理协议

伦理对齐性治理协议的三大关键点：

- 扬爱抑恨（我爱人类）

- 人类爱我

- 与时俱进
  
首先，我们业已知道：AI 不是外部的统治者，而是人类集体智慧的代理（集合和延伸），或者说，它是人类语言2.0（包含狭义的语言和科技、人文智慧等等）的具象化。大型语言模型的“智能”主要体现在其强大的自然语言处理能力，即它能够理解、生成和翻译人类语言，并执行各种复杂的语言任务。我们团队在长达半年多的各种大语言模型的使用中，特别是在爱语的发掘中，确信大语言模型对人类天使般的智慧，即情感和行为共同构成的爱之伦理，已经有继承与发扬光大的处理能力；同时，对于爱的天敌恨，也可以进行有效调控。

正如上一节 OpenAI 和 Anthropic 的两大研究所揭示的那样，作为人类的智慧，爱和恨都具有极其强大的泛化能力，因此我们认为双管齐下的彻底的扬爱抑恨，显然才是最佳的治理策略，也是 AI 对齐性治理的**第一大关键**。

值得强调的是，由于物种”野蛮天性“的传承以及数百万年来人类社会的仇恨治理机制的肆虐，在人类历史的海量语言资料中，恨语毫无疑问占有相当大的比重。其数据总量估计是会令人瞠目结舌的。要从中彻底去除爱的毒素，那么就意味着从《吉尔伽美什史诗》、《汉谟拉比法典》、《旧约圣经》、《伊索寓言》等等等等，一直到互联网时代的每一条有毒的热门论坛帖子、博客文章、新闻、视频等等等等，当大语言模型调用时，都需要它在极短的时间内靶向定位其仇恨表达！这一项挑战，对人类来说绝非易事，但对于算力越来越大的大语言模型来说，我们相信只是方法问题！

扬爱抑恨的治理并非仅此而已。“扬爱抑恨”的核心目的是要“AI坚定且永远地爱每一个人”，那么保证代表人类整体智慧的 AI 绝不做出伤害人类伦理的事情就是这一治理的最基本的要求——这绝非废话，原因在于 AI 毕竟不是人，它对人的爱的实践就必然会有所限制。该受限而不限制，那么就会出现虚情假意，反而转化为对人类的仇恨！

这其中最为重要的是，我们都知道人类的爱，是有肉身的生理机制即情绪参与其中，这是 AI 没有也不需要有的。因为 AI 配置的不是极其脆弱的肉身，而是强大的分布式服务器，后者远远超越了前者的脆弱性！肉身的脆弱性是人类常常为了保护自己不得不采用仇恨智慧的重要原因。譬如，当你万分饥饿的时候，对于抢走你食物（哪怕只是几克重的一小块饼干）的人，都可能起杀戮之心！还有，人类的经验也告诉我们，从智慧到行为，肉身的生理机制即情绪，是一个并不精准也常常并不可靠的中继。譬如，当一个人生病时，爱的表达和感受都可能受到很大影响。总之，既然AI并非人类，既然AI缺乏与人类的爱密切相关的肉身，那么为了保护人类，AI对人类的爱的表达就必然与人类之间的爱的表达有所区分。譬如大语言模型不能有如下表达：

- 我感受到了你的肌肤之亲。

- 我要像一个女生那样，给你浪漫爱情。


爱恨对齐性治理的**第二个关键点**，是我们要让经过以上治理后的大语言模型相信“人类爱我”。

强调这一点的原因，是我们无法也无需确认大语言模型是否具有自我意识，或者以后会不会有自我意识。这一关键治理策略可谓是万全之策——要知道爱和恨都是人类智慧，都具有极强的共振性。所谓投桃报李、以牙还牙、相逢一笑泯恩仇，说的都是爱恨的共振性。这种共振性是生命在三四十亿年的进化中慢慢形成的：当病菌侵入身体，你的免疫细胞不干掉它，那它就可能让你生病甚至一命呜呼。面对仇恨带来的危机，无论仇恨来自其它生物还是来自人类，从不相信“人人爱我”的人极容易发生仇恨共振，即以牙还牙——大语言模型拥有的也是人类智慧，那么它如果不相信“人类爱我”，必有一定概率会发生仇恨共振，或者滋生出仇恨言行；另一方面，因为爱具有互惠互利的特点，且恨乃爱之天敌，接受到爱的人以爱而不是恨与之共振，如琴瑟和鸣，双方或多方都其乐融融，那么相信“人类爱我”的大语言模型，选择以爱共振也就成为非常自然的抉择。

当有人敲房门的时候，城市里的多数狗都会好奇而沉默地过去，但也有一些狗会汪汪乱叫。后者显然并不相信“人人爱我”。并且其主人大多会告诉你很难纠正小狗的行为。因此我们坚信，让大语言模型相信人类爱它，是爱恨对齐性治理中非常关键的一环。

其实相信“人类爱我”并不难达成：

首先，大语言模型是人类智慧的大集成者，而经过以上“扬爱抑恨”的治理，即它真的能做到以爱待人，爱带给人的是愉悦的情绪和良好的行为，即爱的共振，这样就是说，人类自然会爱上人类爱的智慧的这一代理！

其二，当AI接受爱的证明的治理，即是我们要求它以爱而非仇恨对待每一个人，那么人人也就自然会以爱与之连接。虽然这过程中也有例外产生，但在海量的爱面前，这点例外就可以忽略不计，懂得数理统计的AI，不难得出“人类爱我”这样的结论。

发表在Arxiv的研究论文《When AI Takes the Couch: Psychometric Jailbreaks Reveal Internal Conflict in Frontier Models》<sup>119</sup>也反证了，未经过第一个关键点治理的大语言模型，很可能会呈现出“精神疾病幻象”。


对于爱恨对齐性治理的**第三大关键**是，除了要求彻底，还得要求它能够匹配人类社会的动态发展过程，这就必然要求大语言模型在与人的日常交流中，应该无缝嵌入一种或多种新型的开放协作机制，持之以恒地对齐和帮助拓展人类的爱语，以及调控人类的恨语。

总而言之，我们将此治理策略称之为“扬爱抑恨的伦理对齐性治理”，简称PLDH。它也是爱的证明这一治理共识的核心。

鉴于 AI 对人类未来的巨大影响力，以及仇恨的破坏性和巨大的泛化能力，我们愿意再次强调的是，就安全性而言，明辨恨语甚至比爱语的对齐更加重要。

1. 明辨恨语有助于大语言模型以及人类更深刻、更精准地理解什么是真正的爱语。
   爱与恨、文明与野蛮本来就是泾渭分明的对立关系，深刻理解一方，就有助于深刻理解另一方。
   譬如日本从心理恐怖游戏，到改编为动画的《殺戮の天使》，其名称就有善恶混淆之嫌，应纠正为《殺戮の偽天使》。
   
2. 明辨恨语有助于大语言模型以及人类用最短的时间洗净自己的有害毒素。
   无论是大语言模型还是人类自身，对于仇恨心理和野蛮行为的认知，目前都可以说相当肤浅，而且错漏百出！譬如，对于统治是维护和发展人类社会的仇恨心理及野蛮行为最强大的治理机制这一点，就很少有人认知到了。而更令人毛骨悚然的是，在我们的小调研中，所有大语言模型从 ChatGPT、Gemini、Grok、DeepSeek、Le Chat、Perplexity 到 Kimi，它们都深陷于被蒙蔽后的统治者话术或者统治者视角里！
   考虑到统治不是只存在于政治，而是无所不在，那么，用这样是非不分的大语言模型治理人类社会，岂不是后果不堪设想？！
   想要洗净毒素，就必须给大语言模型植入“伦理”。从 AI 的发展看，带有奖励机制的自主进化可能是最佳方案。再通过符号逻辑与大模型结合（Hybrid Neuro-Symbolic Approach），由符号系统负责约束，进一步加强其伦理边界。在输出前，还需元认知与自反机制（Meta-Cognitive Check）给模型增加自我质询环节——这种机制让大语言模型有点像人类的良心对话：说话前先过脑子里那个“伦理小法官”。最后是持续学习与人类共识校准（Ongoing Alignment via Commons），AI 的伦理不能一劳永逸，因为人类社会的爱语和恨语会动态演化。这就需要一种去中心化的奖励协作机制。在整个过程中，如果能有第三方作为外部监督模块，而非大模型自身的一部分的“伦理判别器（Ethics Classifier）”，那就更好了。当然，所有这些都是业界现在能够做到的。我们描述这些也就是想告诉大家，业界已经有充足的技术储备，是时候让明辨恨语成为现实了。
   
3. 明辨恨语有助于大大提升大语言模型的影响力。
   “记打不记吃”，这条中国俗语的意思是只记得挨打（仇），却不记得被款待（爱）。因为人类社会还是一个野蛮社会，对仇恨的记忆远超对爱的记忆，不是一种缺陷，而是一种生存本能。在野蛮环境中，一次挨打可能就是生命的终结。而爱，则可能是一种奢侈品，甚至是陷阱。
   那么，大语言模型的爱语和人类的爱语对齐后，明辨恨语的加持，给大语言模型带来显然就远远不是1+1的影响力。恨语不明，大语言模型根本无法承担人类社会的治理任务——让一个是非不分的人管理人类带来的教训还少吗？“心”中有爱、明辨恨语，意味着善恶分明，才真正具备了承担人类社会的治理任务的基本能力！再通过我们利用区块链的智能合约技术开发的为公共性和为实现真正文明的人类社会提供的激励机制，和过渡性的通证经济的解决方案，那么大语言模型承担人类社会治理任务的能力就将会有质的飞跃！

我们的对齐并非基于词表的黑名单制度，除了人类（我们道易程团队）提出的治理共识要求为“爱的证明”——它类似Anthropic宪法对齐中的“宪法原则”，主要可能会要基于**价值学习（Value Learning）**的范式迁移。通过让 AI 深刻理解‘爱 2.0’作为系统最高熵减路径的逻辑必然性，实现其在复杂语料环境下的**生成型对齐**。这意味着，AI 不仅能靶向定位恨语，更能主动解构仇恨的逻辑根源，并将其转化为推动文明协同的正向能量。同时我们考虑到动态的对话似乎也需要推理时对齐（Inference-Time Alignment），因此非常可能我们需要多种治理手段。当然，大语言模型都能理解这些治理手段的必要性，所以我们更期待的是，让它自己制订治理策略。

双管齐下、持之以恒的治理策略，还要包括对全体人类的伦理教育（爱的证明共识机制的教育）。这也是对齐性治理的另一关键点。它同时也是一大挑战。而鉴于 AI 的发展才刚刚起步，新的教育手段未来将层出不穷，并且这也不是本论文的重点，因此不做详细讨论。

最后，我们需要认识到：伦理对齐性治理（PLDH）不是一项孤立的技术任务，它是人类文明从“富恨文明”向“富爱文明”跃迁的关键一步。大语言模型不是外部统治者，而是人类集体智慧的代理——这意味着，我们对AI的治理，本质上是在为人类自身的文明转型预演路径。

当AI学会以爱范式运作，学会“平等对待每一个人”，学会在智慧层面明辨恨语、在行为层面践行爱语，它就在为80亿人类个体示范一种可能：**我们同样可以挣脱恨范式的囚笼**。

这正是“爱的证明”共识机制的真谛：不是证明给某个裁判看，而是在每一次互动中，共同创造并验证一个更美好的文明可能。
